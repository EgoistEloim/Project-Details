# Project-Details
## Credit Card Related
The whole pipeline is divided into 2 parts: detection and recognition. It's not an end to end pipeline. Megvii will use the self-designed deep learning framework called MegaBrain rather than Pytorch or Tensorflow. So I implemented all the network architechture from scratch mentioned below.
### Detection
In detection part, I implemented [RetinaNet](https://arxiv.org/abs/1708.02002) for detecting the credit card. It's because we need to consider the efficiency of the model after deployment on edge-devices. One-stage method is faster than two-stage method. Here I will introduce the details of RetinaNet.
1. Focal Loss: After the One-stage method obtains the feature map, it will produce dense target proposal regions, and only a small part of these proposal regions are real targets, which causes the classic imbalance of positive and negative training samples in machine learning. It often causes the final calculated training loss to be dominated by negative samples that account for the absolute majority but contain little information (consider 1 positive target vs 1000 negative targets). The key information provided by a small number of positive samples cannot play a normal role in the commonly used training loss, so it cannot be a loss that can provide correct guidance for model training. But after the Two-tage method obtains the proposal, its proposal area is much smaller than the proposal area generated by One-stage, so it will not cause serious category imbalance.
Focal Loss is very simple, that is, a factor is added to the original cross-entropy loss function to make the loss function pay more attention to hard examples. In actual use, the paper proposes to add a alpha balance factor which can produce a slight accuracy increase, the formula is shown below:

<p align="center">
  <img src="https://latex.codecogs.com/gif.latex?FL_%7B%28p_%7Bt%7D%29%7D%3D-%5Calpha%20_%7Bt%7D%281-p_%7Bt%7D%29%5E%7B%5Cgamma%20%7Dlog%28p_%7Bt%7D%29">
</p>

2. Architechture: 
